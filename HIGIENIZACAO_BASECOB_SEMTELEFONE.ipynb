{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lendo base de cobrança GEVENUE e carregando pelo INDEX somente oq é util pra higienizar\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Configuração para exibir todas as colunas no DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Definindo os nomes das colunas\n",
    "header_novo_gevenue = [\n",
    "    \"CÓDIGO DA CONTA\", \"SENHA\", \"PRODUTO\", \"NOME\", \"TIPO DE PESSOA\", \"CPF/CNPJ\",\n",
    "    \"DATA_NASCIMENTO\", \"FILA_COBRANCA\", \"ULT_DATA_SMS\", \"ULT_DATA_CARTA\",\n",
    "    \"ULT_DATA_URA\", \"ULT_DATA_EMAIL\", \"CARTEIRA (REGIÃO)\", \"VENCIMENTO\",\n",
    "    \"Valor Claro Móvel\", \"Valor Claro Residencial\", \"Valor Claro Empresarial\",\n",
    "    \"Valor Claro Fixo\", \"Valor Claro TV\", \"Valor TvExpurgo\", \"Valor Oi\",\n",
    "    \"DATA_NEGATIVACAO\", \"DATA_CADASTRO\", \"STATUS_CONTRATO_NET\", \"EMAIL_01\",\n",
    "    \"EMAIL_02\", \"EMAIL_03\", \"TIPO_DE_ENDERECO_1\", \"ORIGEM_ENDERECO_1\",\n",
    "    \"CIDADE_END_INS\", \"ESTADO_END_INS\", \"CEP_END_INS\", \"TIPO_DE_ENDERECO_2\",\n",
    "    \"ORIGEM_ENDERECO_2\", \"CIDADE_END_FAT\", \"UF_END_FAT\", \"CEP_END_FAT\",\n",
    "    \"DDD_FIXO_1\", \"TEL_FIXO_1\", \"DDD_FIXO_2\", \"TEL_FIXO_2\", \"DDD_FIXO_3\",\n",
    "    \"TEL_FIXO_3\", \"DDD_FIXO_4\", \"TEL_FIXO_4\", \"DDD_CEL_1\", \"TEL_CEL_1\",\n",
    "    \"DDD_CEL_2\", \"TEL_CEL_2\", \"DDD_CEL_3\", \"TEL_CEL_3\", \"DDD_CEL_4\", \"TEL_CEL_4\"\n",
    "]\n",
    "\n",
    "# Definindo o caminho para a pasta onde estão os arquivos .txt\n",
    "caminho = r\"R:\\TI\\TELEFONIA\\BASES CLARO E NET ATIVA\\BASE DE COBRANÇA\\Base de Cobrança GEV\"\n",
    "arquivos = glob.glob(os.path.join(caminho, \"*.txt\"))\n",
    "\n",
    "# Lista de larguras do layout NET COB\n",
    "lista_de_larguras = [\n",
    "    15, 12, 15, 40, 8, 15, 10, 50, 16, 16, 16, 16, 30, 10, 12, 12, 12, 12, 12, 12,\n",
    "    12, 10, 10, 50, 50, 50, 50, 10, 300, 40, 2, 9, 10, 300, 40, 2, 9, 2, 10, 2,\n",
    "    10, 2, 10, 2, 10, 2, 10, 2, 10, 2, 10, 2, 10, 2, 10, 2, 10\n",
    "]\n",
    "\n",
    "# Definindo os índices das colunas de interesse\n",
    "colunas_de_interesse_indices = [0,1,2,3,5,13,24,25,26,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52]\n",
    "\n",
    "# Selecionando as larguras e os nomes das colunas de interesse\n",
    "larguras_interesse = [lista_de_larguras[i] for i in colunas_de_interesse_indices]\n",
    "colunas_interesse = [header_novo_gevenue[i] for i in colunas_de_interesse_indices]\n",
    "\n",
    "# Calculando as larguras cumulativas para pular colunas desnecessárias\n",
    "sum_larguras = 0\n",
    "colunas_interesse_larguras = []\n",
    "for i in range(len(lista_de_larguras)):\n",
    "    if i in colunas_de_interesse_indices:\n",
    "        colunas_interesse_larguras.append((sum_larguras, lista_de_larguras[i]))\n",
    "    sum_larguras += lista_de_larguras[i]\n",
    "\n",
    "# Função personalizada para ler apenas as colunas de interesse\n",
    "def ler_colunas_interesse(linha):\n",
    "    valores = []\n",
    "    for inicio, largura in colunas_interesse_larguras:\n",
    "        valores.append(linha[inicio:inicio+largura].strip())\n",
    "    return valores\n",
    "\n",
    "# Lista para armazenar os DataFrames de cada arquivo\n",
    "dfList = []\n",
    "\n",
    "# Iterar sobre os arquivos na pasta\n",
    "for arquivo in arquivos:\n",
    "    print(f\"Lendo arquivo: {arquivo}\")\n",
    "    \n",
    "    # Lendo o arquivo e selecionando as colunas de interesse\n",
    "    with open(arquivo, 'r', encoding='utf-8') as file:\n",
    "        dados = [ler_colunas_interesse(linha) for linha in file]\n",
    "\n",
    "    # Convertendo os dados para um DataFrame do pandas\n",
    "    df = pd.DataFrame(dados, columns=colunas_interesse)\n",
    "    dfList.append(df)\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "base_cob = pd.concat(dfList, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtrando apenas quem NÃO TEM TELEFONE \n",
    "base_sem_tel = base_cob.query(\"TEL_FIXO_1 == '' and TEL_FIXO_2 == '' and TEL_FIXO_3 == '' and TEL_FIXO_4 == '' and TEL_CEL_1 == '' and TEL_CEL_2 == '' and TEL_CEL_3 == '' and TEL_CEL_4 == '' \")\n",
    "base_sem_tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna de vencimento para datetime\n",
    "base_sem_tel['VENCIMENTO'] = pd.to_datetime(base_sem_tel['VENCIMENTO'], format='%d/%m/%Y')\n",
    "\n",
    "# Obter a data atual\n",
    "data_atual = datetime.now()\n",
    "\n",
    "# Calcular os dias em atraso\n",
    "base_sem_tel['ATRASO'] = (data_atual - base_sem_tel['VENCIMENTO']).dt.days\n",
    "\n",
    "# Substituir valores negativos por zero (caso não estejam em atraso)\n",
    "base_sem_tel['ATRASO'] = base_sem_tel['ATRASO'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "\n",
    "## Removendo duplicado por cpf e organizando o layout\n",
    "base_sem_tel = base_sem_tel[['CÓDIGO DA CONTA', 'SENHA', 'PRODUTO', 'NOME', 'CPF/CNPJ', 'VENCIMENTO','ATRASO','EMAIL_01', 'EMAIL_02', 'EMAIL_03']].drop_duplicates(['CPF/CNPJ'])\n",
    "\n",
    "### Filtrando a faixa que podem cobrar\n",
    "base_sem_tel = base_sem_tel.query(\"ATRASO < 1785\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sem_tel.to_csv(r\"R:\\TI\\TELEFONIA\\Mailings Prontos\\2024\\Agosto\\05\\Jorgean/base_sem_tel_para_higienizar.csv\",index=False,sep=';')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
